"""
üåê LLM Provider Service
======================

Servi√ßo para comunica√ß√£o com provedores de LLM.
Reutiliza a l√≥gica existente do projeto original.

Suporta m√∫ltiplos provedores conforme requisitos do PRD:
- Azure OpenAI
- OpenAI
- OpenRouter
"""

import os
import httpx
from openai import AzureOpenAI, OpenAI
import logging

logger = logging.getLogger(__name__)

def call_llm_api(final_prompt: str) -> str:
    """
    üåê Conecta-se a um provedor de LLM baseado na configura√ß√£o
    
    Implementa√ß√£o baseada na vers√£o otimizada de src/mcp_server/services/llm_service.py
    """
    # Verificar se h√° chaves de API configuradas
    azure_key = os.getenv('AZURE_OPENAI_API_KEY')
    openai_key = os.getenv('OPENAI_API_KEY')
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    
    if not any([azure_key, openai_key, openrouter_key]):
        logger.warning("‚ö†Ô∏è Nenhuma chave de API configurada. Retornando dados de demonstra√ß√£o.")
        return _create_demo_response()
    
    provider = os.getenv("LLM_PROVIDER", "openrouter").lower()
    logger.info(f"ü§ñ Orquestra√ß√£o de Contexto - Provedor: {provider}")
    
    # Configura√ß√£o SSL (False para desenvolvimento, True para produ√ß√£o)
    ssl_verify = os.getenv("SSL_VERIFY", "true").lower() == "true"
    http_client = httpx.Client(verify=ssl_verify)

    try:
        client = None
        model_name = ""

        if provider == "azure":
            # Azure OpenAI
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            model_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
            
            if not all([api_key, azure_endpoint, model_name]):
                raise ValueError("Credenciais do Azure n√£o configuradas no .env")
            
            client = AzureOpenAI(
                api_key=api_key,
                api_version="2024-02-01",
                azure_endpoint=azure_endpoint,
                http_client=http_client
            )

        elif provider == "openai":
            # OpenAI
            api_key = os.getenv("OPENAI_API_KEY")
            model_name = os.getenv("OPENAI_MODEL", "gpt-4o")
            
            if not api_key:
                raise ValueError("Credencial OPENAI_API_KEY n√£o configurada no .env")
            
            client = OpenAI(api_key=api_key, http_client=http_client)

        elif provider == "openrouter":
            # OpenRouter  
            api_key = os.getenv("OPENROUTER_API_KEY")
            model_name = os.getenv("OPENROUTER_MODEL", "anthropic/claude-3.5-sonnet")
            
            if not api_key:
                raise ValueError("Credencial OPENROUTER_API_KEY n√£o configurada no .env")
            
            client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=api_key,
                http_client=http_client
            )

        else:
            raise ValueError(f"Provedor de LLM '{provider}' n√£o suportado.")

        # Fazer chamada para o LLM
        logger.info(f"üì§ Enviando prompt para modelo '{model_name}' via {provider}...")
        
        response = client.chat.completions.create(
            model=model_name,
            response_format={"type": "json_object"},  # For√ßa resposta JSON
            messages=[
                {"role": "user", "content": final_prompt}
            ],
            temperature=0.1,  # Baixa temperatura para consist√™ncia
            max_tokens=4000,
            timeout=60
        )

        json_response = response.choices[0].message.content.strip()
        
        logger.info("üéâ Resposta da IA recebida com sucesso!")
        return json_response

    except Exception as e:
        logger.error(f"‚ùå Erro ao chamar API do provedor {provider}: {e}")
        raise
    finally:
        if http_client:
            http_client.close()


def _create_demo_response() -> str:
    """
    üé≠ Cria resposta de demonstra√ß√£o quando n√£o h√° chaves de API
    
    Retorna dados realistas para mostrar a funcionalidade do sistema
    """
    import json
    
    demo_data = {
        "nome_iniciativa": "Sistema Inteligente de An√°lise de Documentos - DEMONSTRA√á√ÉO",
        "tipo_iniciativa": "Moderniza√ß√£o Tecnol√≥gica",
        "classificacao": "Efici√™ncia Administrativa",
        "natureza_iniciativa": "Sistema de IA para an√°lise automatizada",
        "iniciativa_vinculada": "Moderniza√ß√£o Digital MP",
        "objetivo_estrategico_pen_mp": "Moderniza√ß√£o e Efici√™ncia",
        "programa_pen_mp": ["Gest√£o da Inova√ß√£o", "Tecnologia da Informa√ß√£o"],
        "promocao_objetivo_estrategico": "Implementa√ß√£o de IA para automatizar an√°lise de documentos",
        "data_inicial_operacao": "2025-01-01",
        "fase_implementacao": "Teste/Piloto",
        "descricao": "Sistema de demonstra√ß√£o que utiliza intelig√™ncia artificial para an√°lise automatizada de documentos institucionais, extraindo informa√ß√µes estruturadas e preenchendo formul√°rios automaticamente.",
        "estimativa_recursos": "R$ 150.000 (estimativa para demonstra√ß√£o)",
        "publico_impactado": "Servidores do MP-SP, cidad√£os beneficiados pela efici√™ncia",
        "orgaos_envolvidos": "MP-SP, Departamento de TI, Coordenadoria de Gest√£o Estrat√©gica",
        "contatos": "Coordenador de Inova√ß√£o - inovacao@mp.sp.gov.br",
        "desafio_1": "Automatizar processo manual de an√°lise de documentos",
        "desafio_2": "Reduzir tempo de processamento de formul√°rios",
        "desafio_3": "Melhorar precis√£o na extra√ß√£o de dados",
        "resolutividade": "Sistema permite processar documentos 10x mais r√°pido que processo manual",
        "inovacao": "Primeira implementa√ß√£o de IA para an√°lise de documentos no MP-SP",
        "transparencia": "Relat√≥rios autom√°ticos sobre processamento e resultados gerados",
        "proatividade": "Sistema identifica padr√µes e sugere melhorias nos processos",
        "cooperacao": "Integra√ß√£o com sistemas existentes e treinamento de equipes",
        "resultado_1": "Redu√ß√£o de 80% no tempo de an√°lise de documentos",
        "resultado_2": "Aumento de 95% na precis√£o da extra√ß√£o de dados",
        "resultado_3": "Melhoria na satisfa√ß√£o dos usu√°rios em 90%",
        "categoria": "Tecnologia e Inova√ß√£o"
    }
    
    logger.info("üé≠ Retornando dados de demonstra√ß√£o (chaves de API n√£o configuradas)")
    return json.dumps(demo_data, ensure_ascii=False, indent=2)

# Unified provider delegation (if available)
try:
    from packages.institutional.ia.provider import generate_json as unified_generate_json
except Exception:
    unified_generate_json = None


async def generate_json_via_unified(prompt: str, model: str, response_format: dict | None):
    if unified_generate_json:
        return await unified_generate_json(prompt, model, response_format)
    # fallback to existing provider logic if any (demo or openai client)
    try:
        return await create_response_json(prompt, model=model, response_format=response_format)  # type: ignore
    except Exception:
        return {"error": "No provider available"}
